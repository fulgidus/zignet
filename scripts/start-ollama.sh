#!/bin/bash

# Crea la rete se non esiste
docker network create zignet-net 2>/dev/null || true

# Verifica se il container esiste giÃ 
if docker ps -a --format '{{.Names}}' | grep -q '^ollama$'; then
    echo "ğŸ“¦ Container 'ollama' esiste giÃ "
    
    # Verifica se Ã¨ in esecuzione
    if docker ps --format '{{.Names}}' | grep -q '^ollama$'; then
        echo "âœ… Ollama Ã¨ giÃ  in esecuzione!"
        echo ""
        docker ps --filter "name=ollama" --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"
    else
        echo "ğŸ”„ Avvio container esistente..."
        docker start ollama
        echo "âœ… Ollama riavviato!"
    fi
else
    echo "ğŸš€ Creazione nuovo container Ollama con GPU NVIDIA..."
    docker run -d \
      --gpus=all \
      --name ollama \
      --network zignet-net \
      -p 11434:11434 \
      -v ollama:/root/.ollama \
      ollama/ollama:latest
    
    echo "âœ… Ollama container creato con supporto GPU!"
fi

echo ""
echo "ğŸ“ Modelli salvati nel volume Docker: ollama"
echo "ğŸŒ Server: http://localhost:11434"
echo "ğŸ® GPU: NVIDIA (--gpus=all)"
echo ""
echo "Comandi disponibili:"
echo "  ollama pull <model>   # Scarica un modello"
echo "  ollama list           # Lista modelli installati"
echo "  ollama run <model>    # Esegui un modello"
echo ""
echo "ğŸ’¡ Verifica GPU attiva:"
echo "  docker exec ollama nvidia-smi"
echo ""
echo "ğŸš€ I modelli sono persistenti - non verranno persi al riavvio!"